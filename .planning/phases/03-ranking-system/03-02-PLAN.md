---
phase: 03-ranking-system
plan: 02
type: execute
depends_on: ["03-01"]
files_modified: [src/logic/entropy.ts, src/logic/ranking.ts, src/main.ts]
---

<objective>
Implement information gain scoring and combined word ranking.

Purpose: Provide strategic word ranking that maximizes expected word elimination - the mathematically optimal approach for solving Wordle efficiently.
Output: Functions to calculate expected remaining words and a combined ranking algorithm.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-ranking-system/03-01-SUMMARY.md

**Tech available:** Vite, TypeScript
**Established patterns:**
- Types in src/types/index.ts
- Logic modules in src/logic/ directory
- Frequency scoring from 03-01

**Constraining decisions:**
- Phase 2: requiredLetters takes precedence over excludedLetters for duplicate handling

**Key files:**
@src/types/index.ts
@src/logic/frequency.ts
@src/logic/filter.ts
@src/data/words.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create feedback pattern simulator</name>
  <files>src/logic/entropy.ts</files>
  <action>
Create entropy.ts in src/logic/ with:

`simulateFeedback(guess: string, target: string): string` - Given a guess and the actual target word, return a 5-character pattern string representing the feedback:
- 'G' = green (correct letter, correct position)
- 'Y' = yellow (correct letter, wrong position)
- 'X' = gray (letter not in target, or already accounted for)

Handle duplicate letters correctly:
- If guess has "e" twice and target has "e" once, only one gets G or Y (priority: G first, then Y left-to-right)
- Mark remaining duplicate as X

Example: simulateFeedback("speed", "eerie") should handle the duplicate e's correctly.

Export the function.
  </action>
  <verify>Test cases in main.ts:
- simulateFeedback("crane", "crane") === "GGGGG"
- simulateFeedback("crane", "apple") === "XXXYX" (a is yellow, e is not in target position)
- simulateFeedback("speed", "creep") - verify duplicate handling
Log results to console.</verify>
  <done>Function correctly simulates Wordle feedback including duplicate letter edge cases.</done>
</task>

<task type="auto">
  <name>Task 2: Create information gain scorer</name>
  <files>src/logic/entropy.ts</files>
  <action>
Add to entropy.ts:

`calculateExpectedRemaining(guess: string, possibleWords: string[]): number` - For a given guess against a list of possible target words:
1. Group possibleWords by the feedback pattern that guess would produce
2. For each pattern group, the "remaining" count is the group size
3. Expected remaining = sum of (group_size^2) / total_words (this is the expected value)

Lower expected remaining = better guess (eliminates more words on average).

Alternative metric (entropy-based):
`calculateEntropy(guess: string, possibleWords: string[]): number` - Higher entropy = better guess.
Entropy = -sum(p * log2(p)) where p = group_size / total_words

Implement both, export both. The entropy approach is more standard in information theory.
  </action>
  <verify>With a small test list of 10-20 words, verify:
- calculateExpectedRemaining returns sensible values
- calculateEntropy returns positive values, higher for better guesses
- A word that creates many small groups scores better than one creating few large groups</verify>
  <done>Information gain functions calculate expected word elimination correctly.</done>
</task>

<task type="auto">
  <name>Task 3: Create combined ranking function</name>
  <files>src/logic/ranking.ts</files>
  <action>
Create ranking.ts in src/logic/ with:

`rankWords(candidates: string[], possibleTargets: string[], options?: RankingOptions): RankedWord[]`

Where:
```typescript
interface RankingOptions {
  useEntropy?: boolean;      // default: true when possibleTargets.length <= 500
  useFrequency?: boolean;    // default: true
  entropyWeight?: number;    // default: 0.7
  frequencyWeight?: number;  // default: 0.3
}

interface RankedWord {
  word: string;
  score: number;
  entropyScore?: number;
  frequencyScore?: number;
}
```

Algorithm:
1. If possibleTargets.length > 500 and useEntropy not explicitly true, skip entropy (too slow) and use frequency only
2. Calculate entropy score for each candidate (normalize to 0-1 range)
3. Calculate frequency score for each candidate (normalize to 0-1 range)
4. Combined score = (entropyWeight * entropyScore) + (frequencyWeight * frequencyScore)
5. Sort by combined score descending, return top results

Performance note: Entropy calculation is O(candidates * possibleTargets), so for early game (2000+ words), use frequency-only mode. As words narrow down, switch to entropy-weighted mode.

Add types to src/types/index.ts if needed.
  </action>
  <verify>
1. Rank WORD_LIST against itself with frequency-only (>500 words) - should be fast
2. Rank a small filtered list (50 words) with entropy enabled - should produce strategic rankings
3. Log top 10 ranked words with scores for both scenarios</verify>
  <done>Combined ranking works, auto-selects mode based on word count, produces reasonable rankings.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build` succeeds without errors
- [ ] Feedback simulation handles all edge cases including duplicates
- [ ] Entropy calculation produces meaningful scores
- [ ] Combined ranking auto-switches modes based on word count
- [ ] Performance acceptable (< 1s for typical usage)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- No TypeScript errors
- Information gain scoring correctly identifies high-value guesses
- Combined ranking balances speed (frequency) with strategy (entropy)
- Phase 3 complete - ranking system ready for UI integration
</success_criteria>

<output>
After completion, create `.planning/phases/03-ranking-system/03-02-SUMMARY.md`
</output>
